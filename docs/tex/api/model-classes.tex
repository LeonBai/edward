\title{Classes of Models}

{{navbar}}

\subsubsection{Classes of Models}

...

\subsubsection{Directed Graphical Models}

\subsubsection{Neural Networks}

\subsubsection{Conditionally Specified Undirected Models}

The above certainly supports directed graphical models.

Where does the binding go?
(1) model
+ no functionality is really present in order to do this. just like
with the loss of information with plates vs vectorizatoin, we lose
information about the random variable tying. all these must go into
inference.
(2) inference

For how the tying works, see inference.

TODO tie not needed, c.f., maja
tie : dict of tf.Tensor to RandomVariable
  TODO describe
  as with the other dictionaries, it is not symmetrical. what does
  tying really mean for two random variables/nodes? one must replace
  the other. note this is different from parameter tying, which is
  possibly simply by having things take in the same tf.variable as
  argument.

\subsubsection{Bayesian Nonparametrics and Probabilistic Programs}

We support stochastic control flow, extending control flow ops to use
with the random variables here. This allows us to perform things like
a stochastic while loop, which is used in a stick breaking
construction of a Dirichlet process sampler. We don't support
recursion specifically because TensorFlow can't. However, we can do it
in via something converted from a while loop.

{{autogenerated}}
